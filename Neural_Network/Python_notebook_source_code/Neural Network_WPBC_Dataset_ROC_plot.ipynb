{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## We are trying to build a neural network over a set of 5 features selected manually from the flu dataset. In this problem, the target variable us Flu . We will be starting with one hidden layer neural network and will perform cross validation. Our evaluation will be the visualization of AUC curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAjEzs7I4gZiZWVn+P638SgaATdOrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a566e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Model is 55.000\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "from random import seed\n",
    "import random\n",
    "from random import randrange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "''' Initialize the network '''\n",
    "def init_network(numinputs, numhiddenlayer, numoutputs):\n",
    "    net=list()\n",
    "    # hidden layer\n",
    "    HiddenLayer = [{'weights':[np.random.uniform() for i in range(numinputs+1)]} for i in range(numhiddenlayer)]\n",
    "    net.append(HiddenLayer)\n",
    "    OutputLayer = [{'weights':[np.random.uniform() for i in range(numhiddenlayer+1)]} for i in range(numoutputs)]\n",
    "    net.append(OutputLayer)\n",
    "    return net\n",
    "\n",
    "''' Transfer activation function for the neuron '''\n",
    "\n",
    "def transferFunction(actn):\n",
    "    return 1.0/(1.0+exp(-actn))\n",
    "\n",
    "'''Calculation of activation of neuron from an input '''\n",
    "\n",
    "def activateFunction(wts, inp):\n",
    "    activaN = wts[-1]\n",
    "    for i in range(len(wts)-1):\n",
    "        activaN+=wts[i]*inp[i]\n",
    "    return activaN\n",
    "\n",
    "''' Forward Propagation of the network '''\n",
    "\n",
    "def forwardPropagationNet(netK, row):\n",
    "    inps = row\n",
    "    for layer in netK:\n",
    "        newinps=[]\n",
    "        for neuron in layer:\n",
    "            activaN = activateFunction(neuron['weights'], inps)\n",
    "            neuron['output'] = transferFunction(activaN)\n",
    "            newinps.append(neuron['output'])\n",
    "        inps = newinps\n",
    "    return inps, neuron['weights']\n",
    "\n",
    "\n",
    "''' Derivative of the Transfer Function '''\n",
    "def derivativeTransferFunction(op):\n",
    "    return (op)*(1-op)\n",
    "\n",
    "''' Backward Propagation of the network '''\n",
    "\n",
    "def backwardPropagationNet(netK, observed):\n",
    "    for i in reversed(range(len(netK))):\n",
    "        layer = netK[i]\n",
    "        errorlst = list()\n",
    "        if i != len(netK)-1:\n",
    "            for j in range(len(layer)):\n",
    "                e = 0.0\n",
    "                for neuron in netK[i+1]:\n",
    "                    e += (neuron['weights'][j] * neuron['delta'])\n",
    "                errorlst.append(e)\n",
    "        else:\n",
    "            for k in range(len(layer)):\n",
    "                neuron = layer[k]\n",
    "                errorlst.append(observed[k] - neuron['output'])\n",
    "        for p in range(len(layer)):\n",
    "            neuron = layer[p]\n",
    "            neuron['delta'] = errorlst[p] * derivativeTransferFunction(neuron['output'])\n",
    "\n",
    "\n",
    "''' Update Weights of the Network '''\n",
    "def updateWeightsFunction(netK, row, learningRate):\n",
    "    for i in range(len(netK)):\n",
    "        inp = row[:-1]\n",
    "        if i != 0:\n",
    "            inp = [neuron['output'] for neuron in netK[i-1]]\n",
    "        for neuron in netK[i]:\n",
    "            for j in range(len(inp)):\n",
    "                neuron['weights'][j] += learningRate * neuron['delta'] * inp[j]\n",
    "            neuron['weights'][-1] += learningRate * neuron['delta']\n",
    "\n",
    "\n",
    "''' Training the Network.'''\n",
    "\n",
    "def trainingNetwork(netK, trainData, learningRate, epochs, numoutputs):\n",
    "    #print(\"Learning Rate of the network = %.3f\" % (learningRate))\n",
    "    #epocherror = 0\n",
    "    reg_lambda = 0.0001\n",
    "    for epoch in range(epochs):\n",
    "        errorsum = 0\n",
    "        for row in trainData:\n",
    "            outputs, weights = forwardPropagationNet(netK,row)\n",
    "            observed = [0 for i in range(numoutputs)]\n",
    "            #print len(observed)\n",
    "            #print observed\n",
    "            #print row[-1]\n",
    "            #raise KeyboardInterrupt\n",
    "            observed[int(row[-1])] = 1\n",
    "            errorsum -= sum([(observed[i]-outputs[i])**2 for i in range(len(observed))])\n",
    "            errorsum += (reg_lambda/float(2))*np.sum(np.square(weights))\n",
    "            backwardPropagationNet(netK,observed)\n",
    "            updateWeightsFunction(netK,row,learningRate)\n",
    "        #print('Number_of_Epoch=%d, trainingError=%.3f' % (epoch,errorsum))\n",
    "        #epocherror=errorsum\n",
    "    #print(\"Training Accuracy of the Model after Training is %.3f\" % (100+epocherror))\n",
    "\n",
    "\n",
    "''' Cross Validation function '''\n",
    "def splitByCrossValidation(data,nFolds):\n",
    "    dataSplit = list()\n",
    "    copyData = data\n",
    "    foldNumber = int(len(data) / nFolds)\n",
    "    for i in range(nFolds):\n",
    "        fold = list()\n",
    "        while len(fold) < foldNumber :\n",
    "            idx = randrange(len(copyData))\n",
    "            fold.append(copyData.pop(idx))\n",
    "        dataSplit.append(fold)\n",
    "    return dataSplit\n",
    "\n",
    "''' Prediction Function '''\n",
    "def predict(netK,row):\n",
    "    out,_ = forwardPropagationNet(netK,row)\n",
    "    #print \"out\", out\n",
    "    return out.index(max(out))\n",
    "\n",
    "''' Accuracy Metric '''\n",
    "\n",
    "def accuracyCalculation(A,P):\n",
    "    hit = 0\n",
    "    for i in range(len(P)):\n",
    "        if A[i] == P[i]:\n",
    "            hit+=1\n",
    "    return (hit/float(len(A))) * 100.0\n",
    "\n",
    "def printPR(tp,tn,fn,fp):\n",
    "    precision=0; recall=0\n",
    "    #print tp, tn, fn, fp\n",
    "    try:\n",
    "        precision = tp/float(tp+fp)\n",
    "    except ZeroDivisionError:\n",
    "        print #\"error\"\n",
    "    try:\n",
    "        recall = tp/float(tp+fn)\n",
    "    except ZeroDivisionError:\n",
    "        print #\"error\"\n",
    "    return precision, recall, fp/float(fp+tn)\n",
    "    \n",
    "''' this dataset involves two class problem. So we take 1 as Positive and 0 as Negative'''\n",
    "''' Not a good programming style ********* Mind it '''\n",
    "def confusionmatrix(A,P):\n",
    "    tp=0; fp=0; tn=0; fn=0;\n",
    "    for i in range(len(A)):\n",
    "        if int(A[i]) == P[i]:\n",
    "            if int(A[i]) == 1:\n",
    "                tp+=1\n",
    "            else:\n",
    "                tn+=1\n",
    "        else:\n",
    "            if int(A[i]) == 0:\n",
    "                fp+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "    p1,r1,fpr1 = printPR(tp,tn,fn,fp) \n",
    "    print p1,r1,fpr1\n",
    "    tp=0; fp=0; tn=0; fn=0;\n",
    "    \n",
    "def confusionmatrix_new(A,P,label):\n",
    "    tp=0; fp=0; tn=0; fn=0;\n",
    "    for i in range(len(A)):\n",
    "        if int(A[i]) == P[i]:\n",
    "            if int(A[i]) == label:\n",
    "                tp+=1\n",
    "            else:\n",
    "                tn+=1\n",
    "        else:\n",
    "            if int(A[i]) == label:\n",
    "                fn+=1\n",
    "            if P[i] == label:\n",
    "                fp+=1\n",
    "    return tp, tn, fp, fn\n",
    "    '''\n",
    "    for i in range(len(A)):\n",
    "        if int(A[i]) == P[i]:\n",
    "            if int(A[i]) == 0:\n",
    "                tp+=1\n",
    "            else:\n",
    "                tn+=1\n",
    "        else:\n",
    "            if int(A[i]) == 1:\n",
    "                fp+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "    p0,r0,fpr0 = printPR(tp,tn,fn,fp)\n",
    "    print (p0+p1)/float(2), (r0+r1)/float(2), (fpr0+fpr1)/float(2)\n",
    "    '''\n",
    "   #printPR(tp,tn,fn,fp)\n",
    "    \n",
    "    #fscore = 2*precision*recall/float(precision+recall)\n",
    "    #return precision, recall\n",
    "\n",
    "def normlize_dataframe(df):\n",
    "    '''\n",
    "\n",
    "    :param df:\n",
    "    :return: normalized dataframe after Min-max feature scaling (normalization)\n",
    "    '''\n",
    "    df_norm = (df - df.min()) / (df.max()-df.min())\n",
    "    return df_norm\n",
    "\n",
    "def plot_roc(df):\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.scatter(df.fpr, df.tpr, color='darkblue',\n",
    "             lw=lw)#, #label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "    z = np.polyfit(df.fpr, df.tpr, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(df.fpr,p(df.fpr),\"r-\")\n",
    "    plt.plot(df.tpr, p(df.tpr), 'b-')\n",
    "    plt.xlim([0.5, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate (red line)')\n",
    "    plt.ylabel('True Positive Rate ( blue line)')\n",
    "    plt.title('ROC curve : Regularized layer 3 NN and Normalized Dataset')\n",
    "    #plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "''' Main Function '''\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    seed(1)\n",
    "    df = pd.read_csv('../dataset/fluML.csv')\n",
    "    df = df.dropna()\n",
    "    ''' Shifting the target variable to the end'''\n",
    "    Flu = df.Flu.copy(deep=True)\n",
    "    df = df.drop('Flu',1)\n",
    "    df['Flu'] = Flu\n",
    "    #print df.head()\n",
    "    #raise KeyboardInterrupt\n",
    "    newdf = df.copy(deep=True)\n",
    "    cols_list = df.columns.values\n",
    "    #newdf = newdf.drop(cols_list[0], 1)\n",
    "    newdf = newdf.iloc[:,9:17]\n",
    "    newdf = newdf.sample(frac=1).reset_index(drop=True)\n",
    "    newdf = normlize_dataframe(newdf)\n",
    "    newdf = shuffle(newdf)\n",
    "    #print newdf.shape\n",
    "    #print df.shape\n",
    "    #raise KeyboardInterrupt\n",
    "    #print('Data Loaded and Prepared.')\n",
    "    dataset=list()\n",
    "    for rows in newdf.values:\n",
    "        dataset.append(list(rows))\n",
    "    #print np.asarray(dataset).shape\n",
    "    #raise KeyboardInterrupt\n",
    "    numFolds = 7\n",
    "    #print('Now we are performing CrossValidation')\n",
    "    dataSplit = splitByCrossValidation(dataset,numFolds)\n",
    "    resultscore = list()\n",
    "    trainset=list()\n",
    "    testset=list()\n",
    "    tpr_list = list(); fpr_list=list()\n",
    "    TP0 = 0; TN0 = 0; FP0=0; FN0=0;\n",
    "    TP1 = 0; TN1 = 0; FP1=0; FN1=0;\n",
    "    \n",
    "    for fld in dataSplit:\n",
    "        for itr in range(20):\n",
    "            trainset = list(dataSplit)\n",
    "            trainset.remove(fld)\n",
    "            #raise KeyboardInterrupt\n",
    "            #print trainset.remove(fld)\n",
    "            trainset = sum(trainset,[])\n",
    "            testset =list()\n",
    "            for r in fld:\n",
    "                copyrow = list(r)\n",
    "                testset.append(copyrow)\n",
    "                copyrow[-1] = None\n",
    "            numinputs = len(trainset[0])-1\n",
    "            #print(\"Number of the features of the dataset %d\" %(numinputs))\n",
    "            numoutputs = len(set(row[-1] for row in trainset))\n",
    "            #print(\"Number of the labels of the dataset %d\" %(numoutputs))\n",
    "            #print(\"Initializing the Network .......\")\n",
    "            ''' Passing the number of features, number of hidden neurons and number of outputs'''\n",
    "            netK = init_network(numinputs,3,numoutputs)\n",
    "            #print(\"Network Initialized. Training of the Network, begins ....\")\n",
    "            ''' Passing data, network, learning rate, epochs and number of outputs'''\n",
    "            trainingNetwork(netK, trainset, 0.01, 600, numoutputs)\n",
    "            #print('Printing the output of each layer of the network')\n",
    "            #for layer in netK:\n",
    "             #   print(layer)\n",
    "            predictions = list()\n",
    "            for row in testset:\n",
    "                pred = predict(netK, row)\n",
    "                predictions.append(pred)\n",
    "            actualval = [row[-1] for row in fld]\n",
    "            #print actualval\n",
    "            #print \"\\n\"\n",
    "            #print predictions\n",
    "            #raise KeyboardInterrupt\n",
    "            result= accuracyCalculation(actualval,predictions)\n",
    "            tp0, tn0, fp0, fn0 = confusionmatrix_new(actualval, predictions, 0)\n",
    "            tp1, tn1, fp1, fn1 = confusionmatrix_new(actualval, predictions, 1)\n",
    "            tpr_list.append((tp1)/float(tp1+fn1)); fpr_list.append(fp1/float(fp1+tn1))\n",
    "            resultscore.append(result)\n",
    "    ROC_data = pd.DataFrame({'tpr': tpr_list, 'fpr': fpr_list})\n",
    "    plot_roc(ROC_data)\n",
    "    print(\"Accuracy of the Model is %.3f\" %(sum(resultscore)/float(len(resultscore))))\n",
    "    #print('Jobs Ends!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# this plot has been created over normalized dataset but the Neural Network is not regularized. This has been done for layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
