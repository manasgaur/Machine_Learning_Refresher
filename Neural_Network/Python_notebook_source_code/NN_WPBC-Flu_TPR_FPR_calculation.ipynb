{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from math import exp\n",
    "from random import seed\n",
    "import random\n",
    "from random import randrange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "\n",
    "''' Initialize the network '''\n",
    "def init_network(numinputs, numhiddenlayer, numoutputs):\n",
    "    net=list()\n",
    "    # hidden layer\n",
    "    HiddenLayer = [{'weights':[np.random.uniform() for i in range(numinputs+1)]} for i in range(numhiddenlayer)]\n",
    "    net.append(HiddenLayer)\n",
    "    OutputLayer = [{'weights':[np.random.uniform() for i in range(numhiddenlayer+1)]} for i in range(numoutputs)]\n",
    "    net.append(OutputLayer)\n",
    "    return net\n",
    "\n",
    "''' Transfer activation function for the neuron '''\n",
    "\n",
    "def transferFunction(actn):\n",
    "    return 1.0/(1.0+exp(-actn))\n",
    "\n",
    "'''Calculation of activation of neuron from an input '''\n",
    "\n",
    "def activateFunction(wts, inp):\n",
    "    activaN = wts[-1]\n",
    "    for i in range(len(wts)-1):\n",
    "        activaN+=wts[i]*inp[i]\n",
    "    return activaN\n",
    "\n",
    "''' Forward Propagation of the network '''\n",
    "\n",
    "def forwardPropagationNet(netK, row):\n",
    "    inps = row\n",
    "    for layer in netK:\n",
    "        newinps=[]\n",
    "        for neuron in layer:\n",
    "            activaN = activateFunction(neuron['weights'], inps)\n",
    "            neuron['output'] = transferFunction(activaN)\n",
    "            newinps.append(neuron['output'])\n",
    "        inps = newinps\n",
    "    return inps, neuron['weights']\n",
    "\n",
    "\n",
    "''' Derivative of the Transfer Function '''\n",
    "def derivativeTransferFunction(op):\n",
    "    return (op)*(1-op)\n",
    "\n",
    "''' Backward Propagation of the network '''\n",
    "\n",
    "def backwardPropagationNet(netK, observed):\n",
    "    for i in reversed(range(len(netK))):\n",
    "        layer = netK[i]\n",
    "        errorlst = list()\n",
    "        if i != len(netK)-1:\n",
    "            for j in range(len(layer)):\n",
    "                e = 0.0\n",
    "                for neuron in netK[i+1]:\n",
    "                    e += (neuron['weights'][j] * neuron['delta'])\n",
    "                errorlst.append(e)\n",
    "        else:\n",
    "            for k in range(len(layer)):\n",
    "                neuron = layer[k]\n",
    "                errorlst.append(observed[k] - neuron['output'])\n",
    "        for p in range(len(layer)):\n",
    "            neuron = layer[p]\n",
    "            neuron['delta'] = errorlst[p] * derivativeTransferFunction(neuron['output'])\n",
    "\n",
    "\n",
    "''' Update Weights of the Network '''\n",
    "def updateWeightsFunction(netK, row, learningRate):\n",
    "    for i in range(len(netK)):\n",
    "        inp = row[:-1]\n",
    "        if i != 0:\n",
    "            inp = [neuron['output'] for neuron in netK[i-1]]\n",
    "        for neuron in netK[i]:\n",
    "            for j in range(len(inp)):\n",
    "                neuron['weights'][j] += learningRate * neuron['delta'] * inp[j]\n",
    "            neuron['weights'][-1] += learningRate * neuron['delta']\n",
    "\n",
    "\n",
    "''' Training the Network.'''\n",
    "\n",
    "def trainingNetwork(netK, trainData, learningRate, epochs, numoutputs):\n",
    "    #print(\"Learning Rate of the network = %.3f\" % (learningRate))\n",
    "    #epocherror = 0\n",
    "    reg_lambda = 0.0001\n",
    "    for epoch in range(epochs):\n",
    "        errorsum = 0\n",
    "        for row in trainData:\n",
    "            outputs, weights = forwardPropagationNet(netK,row)\n",
    "            observed = [0 for i in range(numoutputs)]\n",
    "            #print len(observed)\n",
    "            #print observed\n",
    "            #print row[-1]\n",
    "            #raise KeyboardInterrupt\n",
    "            observed[int(row[-1])] = 1\n",
    "            errorsum -= sum([(observed[i]-outputs[i])**2 for i in range(len(observed))])\n",
    "            errorsum += (reg_lambda/float(2))*np.sum(np.square(weights))\n",
    "            backwardPropagationNet(netK,observed)\n",
    "            updateWeightsFunction(netK,row,learningRate)\n",
    "        #print('Number_of_Epoch=%d, trainingError=%.3f' % (epoch,errorsum))\n",
    "        #epocherror=errorsum\n",
    "    #print(\"Training Accuracy of the Model after Training is %.3f\" % (100+epocherror))\n",
    "\n",
    "\n",
    "''' Cross Validation function '''\n",
    "def splitByCrossValidation(data,nFolds):\n",
    "    dataSplit = list()\n",
    "    copyData = data\n",
    "    foldNumber = int(len(data) / nFolds)\n",
    "    for i in range(nFolds):\n",
    "        fold = list()\n",
    "        while len(fold) < foldNumber :\n",
    "            idx = randrange(len(copyData))\n",
    "            fold.append(copyData.pop(idx))\n",
    "        dataSplit.append(fold)\n",
    "    return dataSplit\n",
    "\n",
    "''' Prediction Function '''\n",
    "def predict(netK,row):\n",
    "    out,_ = forwardPropagationNet(netK,row)\n",
    "    #print \"out\", out\n",
    "    return out.index(max(out))\n",
    "\n",
    "''' Accuracy Metric '''\n",
    "\n",
    "def accuracyCalculation(A,P):\n",
    "    hit = 0\n",
    "    for i in range(len(P)):\n",
    "        if A[i] == P[i]:\n",
    "            hit+=1\n",
    "    return (hit/float(len(A))) * 100.0\n",
    "\n",
    "def printPR(tp,tn,fn,fp):\n",
    "    precision=0; recall=0\n",
    "    #print tp, tn, fn, fp\n",
    "    try:\n",
    "        precision = tp/float(tp+fp)\n",
    "    except ZeroDivisionError:\n",
    "        print #\"error\"\n",
    "    try:\n",
    "        recall = tp/float(tp+fn)\n",
    "    except ZeroDivisionError:\n",
    "        print #\"error\"\n",
    "    return precision, recall, fp/float(fp+tn)\n",
    "    \n",
    "''' this dataset involves two class problem. So we take 1 as Positive and 0 as Negative'''\n",
    "''' Not a good programming style ********* Mind it '''\n",
    "def confusionmatrix(A,P):\n",
    "    tp=0; fp=0; tn=0; fn=0;\n",
    "    for i in range(len(A)):\n",
    "        if int(A[i]) == P[i]:\n",
    "            if int(A[i]) == 1:\n",
    "                tp+=1\n",
    "            else:\n",
    "                tn+=1\n",
    "        else:\n",
    "            if int(A[i]) == 0:\n",
    "                fp+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "    p1,r1,fpr1 = printPR(tp,tn,fn,fp) \n",
    "    print p1,r1,fpr1\n",
    "    tp=0; fp=0; tn=0; fn=0;\n",
    "    \n",
    "def confusionmatrix_new(A,P,label):\n",
    "    tp=0; fp=0; tn=0; fn=0;\n",
    "    for i in range(len(A)):\n",
    "        if int(A[i]) == P[i]:\n",
    "            if int(A[i]) == label:\n",
    "                tp+=1\n",
    "            else:\n",
    "                tn+=1\n",
    "        else:\n",
    "            if int(A[i]) == label:\n",
    "                fn+=1\n",
    "            if P[i] == label:\n",
    "                fp+=1\n",
    "    return tp, tn, fp, fn\n",
    "    '''\n",
    "    for i in range(len(A)):\n",
    "        if int(A[i]) == P[i]:\n",
    "            if int(A[i]) == 0:\n",
    "                tp+=1\n",
    "            else:\n",
    "                tn+=1\n",
    "        else:\n",
    "            if int(A[i]) == 1:\n",
    "                fp+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "    p0,r0,fpr0 = printPR(tp,tn,fn,fp)\n",
    "    print (p0+p1)/float(2), (r0+r1)/float(2), (fpr0+fpr1)/float(2)\n",
    "    '''\n",
    "   #printPR(tp,tn,fn,fp)\n",
    "    \n",
    "    #fscore = 2*precision*recall/float(precision+recall)\n",
    "    #return precision, recall\n",
    "\n",
    "def normlize_dataframe(df):\n",
    "    '''\n",
    "\n",
    "    :param df:\n",
    "    :return: normalized dataframe after Min-max feature scaling (normalization)\n",
    "    '''\n",
    "    df_norm = (df - df.min()) / (df.max()-df.min())\n",
    "    return df_norm\n",
    "\n",
    "\n",
    "''' Main Function '''\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    seed(1)\n",
    "    df = pd.read_csv('../datasets/fluML.csv')\n",
    "    df = df.dropna()\n",
    "    ''' Shifting the target variable to the end'''\n",
    "    Flu = df.Flu.copy(deep=True)\n",
    "    df = df.drop('Flu',1)\n",
    "    df['Flu'] = Flu\n",
    "    #print df.head()\n",
    "    #raise KeyboardInterrupt\n",
    "    newdf = df.copy(deep=True)\n",
    "    cols_list = df.columns.values\n",
    "    #newdf = newdf.drop(cols_list[0], 1)\n",
    "    newdf = newdf.iloc[:,9:17]\n",
    "    newdf = newdf.sample(frac=1).reset_index(drop=True)\n",
    "    newdf = normlize_dataframe(newdf)\n",
    "    newdf = shuffle(newdf)\n",
    "    #print newdf.shape\n",
    "    #print df.shape\n",
    "    #raise KeyboardInterrupt\n",
    "    #print('Data Loaded and Prepared.')\n",
    "    dataset=list()\n",
    "    for rows in newdf.values:\n",
    "        dataset.append(list(rows))\n",
    "    #print np.asarray(dataset).shape\n",
    "    #raise KeyboardInterrupt\n",
    "    numFolds = 7\n",
    "    #print('Now we are performing CrossValidation')\n",
    "    dataSplit = splitByCrossValidation(dataset,numFolds)\n",
    "    resultscore = list()\n",
    "    trainset=list()\n",
    "    testset=list()\n",
    "    tpr_list = list(); fpr_list=list()\n",
    "    TP0 = 0; TN0 = 0; FP0=0; FN0=0;\n",
    "    TP1 = 0; TN1 = 0; FP1=0; FN1=0;\n",
    "    \n",
    "    for fld in dataSplit:\n",
    "        trainset = list(dataSplit)\n",
    "        trainset.remove(fld)\n",
    "        #raise KeyboardInterrupt\n",
    "        #print trainset.remove(fld)\n",
    "        trainset = sum(trainset,[])\n",
    "        testset =list()\n",
    "        for r in fld:\n",
    "            copyrow = list(r)\n",
    "            testset.append(copyrow)\n",
    "            copyrow[-1] = None\n",
    "        numinputs = len(trainset[0])-1\n",
    "        #print(\"Number of the features of the dataset %d\" %(numinputs))\n",
    "        numoutputs = len(set(row[-1] for row in trainset))\n",
    "        #print(\"Number of the labels of the dataset %d\" %(numoutputs))\n",
    "        #print(\"Initializing the Network .......\")\n",
    "        ''' Passing the number of features, number of hidden neurons and number of outputs'''\n",
    "        netK = init_network(numinputs,3,numoutputs)\n",
    "        #print(\"Network Initialized. Training of the Network, begins ....\")\n",
    "        ''' Passing data, network, learning rate, epochs and number of outputs'''\n",
    "        trainingNetwork(netK, trainset, 0.01, 600, numoutputs)\n",
    "        #print('Printing the output of each layer of the network')\n",
    "        #for layer in netK:\n",
    "         #   print(layer)\n",
    "        predictions = list()\n",
    "        for row in testset:\n",
    "            pred = predict(netK, row)\n",
    "            predictions.append(pred)\n",
    "        actualval = [row[-1] for row in fld]\n",
    "        #print actualval\n",
    "        #print \"\\n\"\n",
    "        #print predictions\n",
    "        #raise KeyboardInterrupt\n",
    "        result= accuracyCalculation(actualval,predictions)\n",
    "        tp0, tn0, fp0, fn0 = confusionmatrix_new(actualval, predictions, 0)\n",
    "        TP0+=tp0; TN0+=tn0; FP0+=fp0; FN0+=fn0;\n",
    "        tp1, tn1, fp1, fn1 = confusionmatrix_new(actualval, predictions, 1)\n",
    "        TP1+=tp1; TN1+=tn1; FP1+=fp1; FN1+=fn1;\n",
    "        resultscore.append(result)\n",
    "    print \"for label 0:\", TP0, TN0, FP0, FN0\n",
    "    print \"for label 1:\", TP1, TN1, FP1, FN1\n",
    "    print \"True Positive rate (recall/TPR) : \", float(TP0+TP1)/float(TP0+TP1+FN0+FN1)\n",
    "    print \"False Positive rate (FPR):\", float(FP0+FP1)/float(FP0+FP1+TN0+TN1)\n",
    "    print(\"Accuracy of the Model is %.3f\" %(sum(resultscore)/float(len(resultscore))))\n",
    "    print('Jobs Ends!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
